{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow - Multi-Layer Perceptron on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Project Scope: To predict what number is written down based solely on the image data in the form of an array\n",
    "* Data source: MNIST data set of [handwritten digits](http://yann.lecun.com/exdb/mnist/). The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries & Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# For display in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "dataset = input_data.read_data_sets(\"yann.lecun.com/exdb/mnist/\",\n",
    "                                    one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets  analyze and visualize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "5000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print (i.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see we have 55000 images for training, 5000 for validation, 10000 for testing of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lets us know that there are 55000 images and each one is 784 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check particular image\n",
    "dataset.train.images[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number = dataset.train.images[5].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23137257, 0.6392157 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.7607844 , 0.43921572, 0.07058824, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01568628, 0.5176471 ,\n",
       "        0.93725497, 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.627451  , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5372549 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.75294125,\n",
       "        0.9960785 , 0.9921569 , 0.8980393 , 0.0509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01568628, 0.5372549 , 0.9843138 , 0.9921569 ,\n",
       "        0.9568628 , 0.50980395, 0.19215688, 0.07450981, 0.01960784,\n",
       "        0.6392157 , 0.9921569 , 0.8235295 , 0.03529412, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.37254903, 0.9921569 , 0.9921569 , 0.8431373 ,\n",
       "        0.1764706 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.6117647 , 0.9921569 , 0.68235296, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.8431373 , 0.9960785 , 0.8117648 , 0.09019608,\n",
       "        0.        , 0.        , 0.        , 0.03921569, 0.3803922 ,\n",
       "        0.85098046, 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.83921576, 0.9921569 , 0.2784314 , 0.        ,\n",
       "        0.        , 0.00784314, 0.19607845, 0.8352942 , 0.9921569 ,\n",
       "        0.9960785 , 0.7058824 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.83921576, 0.9921569 , 0.19215688, 0.        ,\n",
       "        0.        , 0.19607845, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.7176471 , 0.04705883, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7803922 , 0.9921569 , 0.95294124, 0.7686275 ,\n",
       "        0.62352943, 0.95294124, 0.9921569 , 0.9686275 , 0.5411765 ,\n",
       "        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16470589, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.9921569 , 0.39607847, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23137257, 0.58431375, 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        1.        , 0.9960785 , 0.6862745 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.13333334, 0.75294125,\n",
       "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.7843138 ,\n",
       "        0.53333336, 0.89019614, 0.9450981 , 0.27058825, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333334, 0.9686275 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.77647066, 0.48235297, 0.07058824,\n",
       "        0.        , 0.19607845, 0.9921569 , 0.8352942 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2784314 , 0.9686275 , 0.9921569 , 0.9294118 ,\n",
       "        0.75294125, 0.2784314 , 0.02352941, 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.5019608 , 0.9803922 , 0.21176472,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.46274513, 0.9921569 , 0.8705883 , 0.14117648,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.03137255, 0.7176471 , 0.9921569 , 0.227451  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.46274513, 0.9960785 , 0.54509807, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.05490196, 0.7294118 , 0.9960785 , 0.9960785 , 0.227451  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2784314 , 0.9686275 , 0.9686275 , 0.54509807,\n",
       "        0.0627451 , 0.        , 0.        , 0.07450981, 0.227451  ,\n",
       "        0.87843144, 0.9921569 , 0.9921569 , 0.8313726 , 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.42352945, 0.9921569 , 0.9921569 ,\n",
       "        0.92549026, 0.6862745 , 0.6862745 , 0.9686275 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.77647066, 0.16862746, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2627451 , 0.8352942 , 0.8980393 ,\n",
       "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.83921576, 0.48627454, 0.02352941, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09019608,\n",
       "        0.60784316, 0.60784316, 0.8745099 , 0.7843138 , 0.46274513,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e504e1dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(number)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIn/HDR9CLRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e50330a550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(number,cmap='gist_gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e503403e10>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADQAAAD8CAYAAAA4w4cyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niJ9jaVANzyEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e50333ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.train.images[5].reshape(784,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5032e3400>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAD8CAYAAADpLRYuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e503421748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.train.images[5].reshape(784,1),aspect=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Multi-Layer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Identifying Factors\n",
    "    * Number of hidden layers: for this model we will use 2 hidden layers\n",
    "    * n_samples: mnist.train.num_examples\n",
    "    * n_input = 784 # number of inputs\n",
    "    * n_outputs= 10 # will have total 10 output classes (0-9 digits)\n",
    "    * n_hidden1 = 256 # first hidden layer features\n",
    "    * n_hidden2 = 256 # second hidden layer features\n",
    "    * Weights: Because we got 2 hidden layers, we need to define 3 sets of weights \n",
    "    * Bias: Because we got 2 hidden layers, we need to define 3 sets of bias\n",
    "    * learning_rate: 0.01 # How quickly to adjust the cost function\n",
    "    * training_epochs = 15 # How many training cycles to go through\n",
    "    * batch_size = 100 # Size of the 'batches' of training data\n",
    "    \n",
    "    Steps to create Model\n",
    "    * Step1: First, we will receive input data array and send it to first hidden layer\n",
    "    * Step2: Each node of fist hidden layer will calculating activation using inputs,weights,bias\n",
    "    * Step3: Will continue on to the next hidden layer, and so on until the final output layer\n",
    "    * Step4: Once data reached Output layer, we will evaluate it using cost/loss function\n",
    "    * Step5: We will apply an Adam optimization function adjusting weight values to minimize the cost\n",
    "    * We can use learning rate to adjust how quickly to apply optimization. The lower the rate the higher the possibility for accurate training results, but that comes at the cost of having to wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Neural Network Parameters **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = dataset.train.num_examples\n",
    "n_input = 784 \n",
    "n_outputs = 10\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "weights = {'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "           'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "           'out': tf.Variable(tf.random_normal([n_hidden_2, n_outputs]))\n",
    "          }\n",
    "biases = {'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "          'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "          'out': tf.Variable(tf.random_normal([n_outputs]))\n",
    "         }\n",
    "learning_rate = 0.001\n",
    "training_epochs = 25\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Inputs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Function to create activation and output **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x : Place Holder for Data Input\n",
    "    weights: Dictionary of weights\n",
    "    biases: Dicitionary of biases\n",
    "    '''\n",
    "    \n",
    "    # First Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Last Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Creating model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cost and Optimization functions **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=pred))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Session\n",
    "\n",
    "We have two loops, the outer loop which runs the epochs, and the inner loop which runs the batches for each epoch of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HOME\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost=209.5311\n",
      "Epoch: 2 cost=44.8940\n",
      "Epoch: 3 cost=28.4588\n",
      "Epoch: 4 cost=19.8553\n",
      "Epoch: 5 cost=14.5109\n",
      "Epoch: 6 cost=10.9304\n",
      "Epoch: 7 cost=8.1527\n",
      "Epoch: 8 cost=6.2046\n",
      "Epoch: 9 cost=4.5512\n",
      "Epoch: 10 cost=3.5662\n",
      "Epoch: 11 cost=2.6851\n",
      "Epoch: 12 cost=2.0819\n",
      "Epoch: 13 cost=1.5495\n",
      "Epoch: 14 cost=1.2307\n",
      "Epoch: 15 cost=1.1041\n",
      "Epoch: 16 cost=0.7928\n",
      "Epoch: 17 cost=0.6393\n",
      "Epoch: 18 cost=0.6253\n",
      "Epoch: 19 cost=0.6026\n",
      "Epoch: 20 cost=0.5014\n",
      "Epoch: 21 cost=0.4506\n",
      "Epoch: 22 cost=0.3968\n",
      "Epoch: 23 cost=0.3941\n",
      "Epoch: 24 cost=0.3912\n",
      "Epoch: 25 cost=0.3002\n",
      "Model has completed 25 Epochs of Training\n"
     ]
    }
   ],
   "source": [
    "# Launch the session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Intialize all the variables\n",
    "sess.run(init)\n",
    "\n",
    "# Training Epochs\n",
    "# Essentially the max amount of loops possible before we stop\n",
    "# May stop earlier if cost/loss limit was set\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    # Start with cost = 0.0\n",
    "    avg_cost = 0.0\n",
    "\n",
    "    # Convert total number of batches to integer\n",
    "    total_batch = int(n_samples/batch_size)\n",
    "\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "\n",
    "        # Grab the next batch of training data and labels\n",
    "        batch_x, batch_y = dataset.train.next_batch(batch_size)\n",
    "\n",
    "        # Feed dictionary for optimization and loss value\n",
    "        # Returns a tuple, but we only need 'c' the cost\n",
    "        # So we set an underscore as a \"throwaway\"\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"Epoch: {} cost={:.4f}\".format(epoch+1,avg_cost))\n",
    "\n",
    "print(\"Model has completed {} Epochs of Training\".format(training_epochs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluations\n",
    "\n",
    "Tensorflow comes with some built-in functions to help evaluate our model, including tf.equal and tf.cast with tf.reduce_mean.\n",
    "\n",
    "**tf.equal():** The tf.equal() operator is an elementwise operator. Assuming x and y are the same shape (as they are in your example) tf.equal(x, y) will produce a tensor with the same shape, where each element indicates whether the corresponding elements in x and y are equal. Therefore, sess.run(tf.equal(y, y)) in your program will return the array [True, True, True]\n",
    "\n",
    "**tf.cast():** To convert the boolean values (False and True) into 0 and 1 \n",
    "\n",
    "**tf.reduce_mean:** To calculate the mean of tensor elements along various dimensions of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9557\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "correct_predictions = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "correct_predictions = tf.cast(correct_predictions, \"float\")\n",
    "accuracy = tf.reduce_mean(correct_predictions)\n",
    "print(\"Accuracy:\", accuracy.eval({x: dataset.test.images, y: dataset.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude our model acheived 95% accuracy in predecting the numbers based on the images from MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
